{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "K Nearest Neighbors.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prav2909/Machine-Learning/blob/master/K_Nearest_Neighbors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Beb1ewWczvyc",
        "colab_type": "text"
      },
      "source": [
        "k-nearest neighbors\n",
        "\n",
        "Only used the already imported libraries `numpy` and `matplotlib.pyplot` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LieO4v7azvyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load required packages and dataset. Do not modify.\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_iris_dataset():\n",
        "    from sklearn import datasets\n",
        "    iris = datasets.load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    return X, y\n",
        "    \n",
        "X, y = load_iris_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlQM1FR1zvyn",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOUMIy7pzvyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['setosa', 'versicolor', 'virginica']\n",
        "feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
        "\n",
        "print(f'#samples: {X.shape[0]}')\n",
        "\n",
        "for class_name, class_count in zip(class_names, np.bincount(y)):\n",
        "    print(f'- class {class_name}: {class_count}')\n",
        "print()\n",
        "    \n",
        "mean = np.mean(X, axis=0)\n",
        "std = np.std(X, axis=0)\n",
        "for feature_idx, feature_name in enumerate(feature_names):\n",
        "    print(f'{feature_name}:')\n",
        "    print(f'- mean: {mean[feature_idx]:.2f}')\n",
        "    print(f'- std: {std[feature_idx]:.2f}')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMFZhWmPzvys",
        "colab_type": "text"
      },
      "source": [
        "3) Visualizing the variables Sepal length and Petal length in a scatter plot (Sepal length on the x-axis, petal length on the y-axis). Coloring each point of the plot according to its class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqfX6Il1zvyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    ax.scatter(X[y == class_idx, 0], X[y == class_idx, 2], label=class_name)\n",
        "ax.set_xlabel('sepal length [cm]')\n",
        "ax.set_ylabel('petal length [cm]')\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv3m28sDzvyw",
        "colab_type": "text"
      },
      "source": [
        "4) Spliting the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJDVnYbHzvyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(X, y):\n",
        "    \"\"\"\n",
        "    Returns X_train, X_test, y_train, y_test, \n",
        "        where X_train and X_test are the input features of the training and test set,\n",
        "        and y_train and y_test are the class labels of the training and test set.\n",
        "    \"\"\"\n",
        "    np.random.seed(2020)  # Ensure that the random split always returns the same result.\n",
        "    \n",
        "    threshold = int(0.7*X.shape[0])\n",
        "    rnd_idx = np.random.permutation(X.shape[0])\n",
        "    \n",
        "    X_train = X[rnd_idx[:threshold]]\n",
        "    X_test = X[rnd_idx[threshold:]]\n",
        "    y_train = y[rnd_idx[:threshold]]\n",
        "    y_test = y[rnd_idx[threshold:]]\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
        "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
        "assert X_train.shape[1] == X_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEUzwrZ2zvy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_min = np.min(X_train, axis=0)\n",
        "X_max = np.max(X_train, axis=0)\n",
        "\n",
        "def min_max_scale(X):\n",
        "    return (X - X_min) / (X_max - X_min)\n",
        "\n",
        "X_train = min_max_scale(X_train)\n",
        "X_test = min_max_scale(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrzWFV07zvy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KNearestNeighbors(object):\n",
        "    def __init__(self, k, distance_metric='uniform'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        This functions saves the training data to be used during the prediction.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Returns a vector of shape (n,) if X has shape (n,d), \n",
        "        where n is the number of samples and d is the number of features.\n",
        "        \"\"\"\n",
        "        if self.distance_metric == 'uniform':\n",
        "            dist = euclidean_distance\n",
        "        else:\n",
        "            dist = self.distance_metric\n",
        "            \n",
        "        # Compute pairwise distances between inputs and training samples.\n",
        "        pw_distances = np.array([[dist(x1, x2) for x1 in X] for x2 in self.X])\n",
        "        # Identify k nearest neighbors for each input sample.\n",
        "        neighbors = np.argsort(pw_distances, axis=0)[:self.k].T\n",
        "        \n",
        "        labels = []\n",
        "        for idx, nb in enumerate(neighbors):\n",
        "            candidate_labels = np.unique(y_train[nb])\n",
        "            candidate_weights = []\n",
        "\n",
        "            for candidate in candidate_labels:\n",
        "                if self.distance_metric == 'uniform': # uniform weights\n",
        "                    candidate_weight = np.sum(self.y[nb] == candidate)\n",
        "                else: # distance-weighted\n",
        "                    weights = 1.0/pw_distances[nb, idx][self.y[nb] == candidate]\n",
        "                    # If distance is 0, the corresponding weight will be infinity,\n",
        "                    # which results in us just looking up the correct label or performing 1-NN.\n",
        "                    candidate_weight = np.sum(weights)\n",
        "                \n",
        "                candidate_weights.append(candidate_weight)\n",
        "            \n",
        "            # Select the class label with highest weight.\n",
        "            label_idx = np.argmax(candidate_weights)\n",
        "            label = candidate_labels[label_idx]\n",
        "            labels.append(label)\n",
        "        \n",
        "        return np.array(labels)\n",
        "\n",
        "    \n",
        "def euclidean_distance(x1, x2):\n",
        "    \"\"\"\n",
        "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr9TgDPuzvzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_pred, y_true):\n",
        "    # We compute the macro-average\n",
        "    labels = set(y_pred).union(set(y_true))\n",
        "    precisions = list()\n",
        "    for label in labels:\n",
        "        tp, fp, _, _ = tp_fp_tn_fn(y_pred, y_true, label)\n",
        "        if (tp + fp) == 0:\n",
        "            prec = 0\n",
        "        else:\n",
        "            prec = tp / (tp + fp)\n",
        "        precisions.append(prec)\n",
        "    return np.mean(precisions)\n",
        "\n",
        "\n",
        "def recall(y_pred, y_true):\n",
        "    # We compute the macro-average\n",
        "    labels = set(y_pred).union(set(y_true))\n",
        "    recalls = list()\n",
        "    for label in labels:\n",
        "        tp, _, _, fn = tp_fp_tn_fn(y_pred, y_true, label)\n",
        "        recalls.append(tp / (tp + fn))\n",
        "    return np.mean(recalls)\n",
        "\n",
        "\n",
        "def f1score(y_pred, y_true):\n",
        "    # We compute the macro-average\n",
        "    labels = set(y_pred).union(set(y_true))\n",
        "    f1scores = list()\n",
        "    for label in labels:\n",
        "        tp, fp, _, fn = tp_fp_tn_fn(y_pred, y_true, label)\n",
        "        if (tp + fp) == 0:\n",
        "            prec = 0\n",
        "        else:\n",
        "            prec = tp / (tp + fp)\n",
        "        rec = tp / (tp + fn)\n",
        "        f1scores.append(2 * (prec * rec) / (prec + rec))\n",
        "    return np.mean(f1scores)\n",
        "\n",
        "\n",
        "def tp_fp_tn_fn(y_pred, y_true, positive_label):\n",
        "    # Count true positive, false positives, true negatives, false negatives for a specific class.\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for yp, yt in zip(y_pred, y_true):\n",
        "        if yp == yt and yt == positive_label: # tp\n",
        "            tp += 1\n",
        "        elif yp != yt and yt == positive_label: # fp\n",
        "            fp += 1\n",
        "        elif yp == yt and yt != positive_label: # tn\n",
        "            tn += 1\n",
        "        else: # fn\n",
        "            fn += 1\n",
        "    return tp, fp, tn, fn\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8-ikSwvzvzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ks = (1, 3, 5)\n",
        "metrics = ('uniform', 'euclidean')\n",
        "hyperparameters = [(k, metric) for metric in metrics for k in ks]\n",
        "\n",
        "scores = []\n",
        "for k, metric in hyperparameters:\n",
        "        classifier = KNearestNeighbors(\n",
        "            k=k, \n",
        "            distance_metric='uniform' if metric == 'uniform' else euclidean_distance\n",
        "        )\n",
        "        classifier.fit(X_train, y_train)\n",
        "        yhat_train = classifier.predict(X_train)\n",
        "        yhat_test = classifier.predict(X_test)\n",
        "                \n",
        "        scores.append([\n",
        "            [fnc(yhat, y) for fnc in (precision, recall, f1score)] \n",
        "            for yhat, y in ((yhat_train, y_train), (yhat_test, y_test))\n",
        "        ])\n",
        "        \n",
        "scores = np.array(scores)\n",
        "ks = np.array(ks)\n",
        "fig, ax = plt.subplots(3, 2, figsize=(8, 8), sharex=True, sharey=True)\n",
        "for row in range(3):\n",
        "    for col in range(2):\n",
        "        ax[row, col].bar(ks-0.25, scores[:3, col, row], width=0.5, label='Uniform')\n",
        "        ax[row, col].bar(ks+0.25, scores[3:, col, row], width=0.5, label='Euclidian')\n",
        "        ax[row, col].set_ylim((0.8, 1.0))\n",
        "        \n",
        "ax[0, 0].set_ylabel('Precision')\n",
        "ax[1, 0].set_ylabel('Recall')\n",
        "ax[2, 0].set_ylabel('F1-Score')\n",
        "ax[0, 0].set_title('Training')\n",
        "ax[0, 1].set_title('Test')\n",
        "ax[-1, 0].set_xlabel('k')\n",
        "ax[-1, 1].set_xlabel('k')\n",
        "ax[-1, 0].set_xticks(ks)\n",
        "ax[0, 1].legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIsUjMf3zvzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}